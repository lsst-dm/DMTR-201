{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook for Acceptance Test Campaign related to LSST Science Pipelines Release 19.0.0\n",
    "\n",
    "This test will be executed on the LSST Science Platform Notebook Aspect, initialized with Science Pipelines release `r19-0-0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases LVV-T1754-1755: Verify the Calculation of Ellipticity Residuals and Correlations, LVV-T1758-1759: Verify Calculation of Photometric Performance Metrics, LVV-T1745-1753: Verify Calculation of Astrometric Performance Metrics\n",
    "\n",
    "Verify that the DMS includes software to enable the calculation of the ellipticity residuals and correlation metrics, the photometric performance metrics, and the astrometric performance metrics defined in the OSS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tests are performed by running `validate_drp` on a precursor dataset (in this case, HSC-RC2). This was done on the development cluster (lsst-dev) at NCSA. This notebook simply shows reports on the results of these runs, and dispatches the jobs to SQuaSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import getpass\n",
    "import requests\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "import json\n",
    "import lsst.verify\n",
    "from lsst.verify import Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs are saved separately by filter. We executed each tract (9615, 9697, and 9813) separately, so that the combination of 3 tracts with 5 filters each yields 15 total output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs from runs of validate_drp:\n",
    "validate_job_9615_G = '/project/jcarlin/verify/RC2_v3/tract9615_HSC-G.json'\n",
    "validate_job_9615_R = '/project/jcarlin/verify/RC2_v3/tract9615_HSC-R.json'\n",
    "validate_job_9615_I = '/project/jcarlin/verify/RC2_v3/tract9615_HSC-I.json'\n",
    "validate_job_9615_Z = '/project/jcarlin/verify/RC2_v3/tract9615_HSC-Z.json'\n",
    "validate_job_9615_Y = '/project/jcarlin/verify/RC2_v3/tract9615_HSC-Y.json'\n",
    "validate_job_9697_G = '/project/jcarlin/verify/RC2_v3/tract9697_HSC-G.json'\n",
    "validate_job_9697_R = '/project/jcarlin/verify/RC2_v3/tract9697_HSC-R.json'\n",
    "validate_job_9697_I = '/project/jcarlin/verify/RC2_v3/tract9697_HSC-I.json'\n",
    "validate_job_9697_Z = '/project/jcarlin/verify/RC2_v3/tract9697_HSC-Z.json'\n",
    "validate_job_9697_Y = '/project/jcarlin/verify/RC2_v3/tract9697_HSC-Y.json'\n",
    "validate_job_9813_G = '/project/jcarlin/verify/RC2_v3/tract9813_HSC-G.json'\n",
    "validate_job_9813_R = '/project/jcarlin/verify/RC2_v3/tract9813_HSC-R.json'\n",
    "validate_job_9813_I = '/project/jcarlin/verify/RC2_v3/tract9813_HSC-I.json'\n",
    "validate_job_9813_Z = '/project/jcarlin/verify/RC2_v3/tract9813_HSC-Z.json'\n",
    "validate_job_9813_Y = '/project/jcarlin/verify/RC2_v3/tract9813_HSC-Y.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the .json saved by a validate_drp run:\n",
    "# Change the filename in the following line to load a different tract/filter combination:\n",
    "with open(validate_job_9615_I) as f:\n",
    "    job = lsst.verify.Job.deserialize(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a metric report in the notebook (use \"spec_tags\" to specify design, stretch, or minimum req level):\n",
    "job.report(spec_tags=['design']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells only need to be executed if one wishes to dispatch the job to the SQuaSH dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clear the extras before dispatching the job to SQuaSH:\n",
    "\n",
    "for k in job.measurements:\n",
    "    job.measurements[k].blobs = {}\n",
    "    job.measurements[k].extras = Blob(str(job.measurements[k].metric_name))\n",
    "    job.measurements[k].blobs[str(job.measurements[k].metric_name)] = job.measurements[k].extras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the SQuaSH API (currently using the sandbox):\n",
    "SQUASH_API_URL = \"https://squash-restful-api-sandbox.lsst.codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up credentials for authentication to SQuaSH:\n",
    "username = getpass.getuser()\n",
    "password = getpass.getpass(prompt='Password for user `{}`: '.format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request an access token:\n",
    "r = requests.post('{}/auth'.format(SQUASH_API_URL), json={'username': username, 'password': password})\n",
    "access_token = r.json()['access_token']\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SQuaSH `metrics` API to upload the metric definition to SQuaSH. This is a one time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the metrics in SQuaSH:\n",
    "r = requests.post('{}/metrics'.format(SQUASH_API_URL), json={'metrics': job.metrics.json}, \n",
    "                  headers={'Authorization': 'JWT {}'.format(r.json()['access_token'])})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for an outstanding Jira ticket requiring jenkins environment\n",
    "job.meta.update({'packages': []})\n",
    "job.meta.update({'env': {'env_name': 'jenkins'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispatch the job to SQuaSH:\n",
    "job.dispatch(api_user=username, api_password=password, api_url=SQUASH_API_URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
