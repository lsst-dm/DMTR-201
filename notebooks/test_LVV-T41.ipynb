{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook for Acceptance Test Campaign related to LSST Science Pipelines Release 19.0.0\n",
    "\n",
    "This test will be executed on the LSST Science Platform Notebook Aspect, initialized with Science Pipelines release `r19-0-0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case LVV-T41: Verify implementation of Generate PSF for Visit Images\n",
    "Verify that Processed Visit Images produced by the DRP and AP pipelines are associated with\n",
    "a model from which one can obtain an image of the PSF given a point on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the version of the Science Pipelines is v19_0_0:\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.persistence as dafPersist\n",
    "import lsst.afw.display as afw_display\n",
    "import lsst.geom as geom\n",
    "from lsst.afw.image import Exposure, Image, PARENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from astropy.visualization import (MinMaxInterval, AsinhStretch, ZScaleInterval, LogStretch, LinearStretch,\n",
    "                                   ImageNormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "zscale = ZScaleInterval()\n",
    "\n",
    "# Set up some plotting defaults:\n",
    "plt.rcParams.update({'figure.figsize' : (12, 8)})\n",
    "plt.rcParams.update({'font.size' : 12})\n",
    "plt.rcParams.update({'axes.linewidth' : 3})\n",
    "plt.rcParams.update({'axes.labelweight' : 3})\n",
    "plt.rcParams.update({'axes.titleweight' : 3})\n",
    "plt.rcParams.update({'ytick.major.width' : 3})\n",
    "plt.rcParams.update({'ytick.minor.width' : 2})\n",
    "plt.rcParams.update({'ytick.major.size' : 8})\n",
    "plt.rcParams.update({'ytick.minor.size' : 5})\n",
    "plt.rcParams.update({'xtick.major.size' : 8})\n",
    "plt.rcParams.update({'xtick.minor.size' : 5})\n",
    "plt.rcParams.update({'xtick.major.width' : 3})\n",
    "plt.rcParams.update({'xtick.minor.width' : 2})\n",
    "plt.rcParams.update({'xtick.direction' : 'in'})\n",
    "plt.rcParams.update({'ytick.direction' : 'in'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use HSC-RC2, as processed using `w_2019_46`, which is the pipelines version that was used to create `v19_0_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output repo is tagged with the Jira ticket number \"DM-22223\":\n",
    "\n",
    "rc2_repo = '/datasets/hsc/repo/rerun/RC/w_2019_46/DM-22223'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the butler repo:\n",
    "butler = dafPersist.Butler(rc2_repo)\n",
    "#m31_fields = butler.subset('calexp', filter='HSC-R', field='M31')\n",
    "\n",
    "# Make a glob of the files in the repo, so we can parse this to get tract/patch IDs:\n",
    "infiles = glob.glob(rc2_repo+'/deepCoadd/HSC-R/*/*/warp-*.fits')\n",
    "#infiles = glob.glob(rc2_repo+'/deepCoadd-results/HSC-R/*/*/calexp-*.fits')\n",
    "print(len(infiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_array = []\n",
    "patch_array = []\n",
    "visit_array = []\n",
    "\n",
    "# Each line of \"infiles\" looks like this (infile[0]):\n",
    "# '/datasets/hsc/repo/rerun/RC/w_2019_46/DM-22223/deepCoadd/HSC-R/9615/8,8/warp-HSC-R-9615-8,8-23902.fits'\n",
    "\n",
    "# Split on the '/', then parse the resulting array. Here's the result of infiles[0].split('/'):\n",
    "\n",
    "#['',\n",
    "# 'datasets',\n",
    "# 'hsc',\n",
    "# 'repo',\n",
    "# 'rerun',\n",
    "# 'RC',\n",
    "# 'w_2019_46',\n",
    "# 'DM-22223',\n",
    "# 'deepCoadd',\n",
    "# 'HSC-R',\n",
    "# '9615',\n",
    "# '8,8',\n",
    "# 'warp-HSC-R-9615-8,8-23902.fits']\n",
    "\n",
    "# So the tract number is third from the end, and patch is second from the end.\n",
    "\n",
    "for ii in range(0, len(infiles)):\n",
    "    parts = infiles[ii].split('/')\n",
    "    tract_array.append(int(parts[-3]))\n",
    "    patch_array.append(parts[-2])\n",
    "    # Split the file name to extract the visit number:\n",
    "    file_str = parts[-1]\n",
    "    file_str2 = file_str.split('.fits')\n",
    "    file_str3 = file_str2[0].split('-')\n",
    "    visit_array.append(file_str3[-1])\n",
    "\n",
    "print('Found %i patches'%(len(patch_array)))\n",
    "        \n",
    "# Assemble in pandas data frame    \n",
    "data = {'tract': tract_array,\n",
    "        'patch': patch_array,\n",
    "        'visit': visit_array}\n",
    "df_tract_patch_visit = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tract_patch_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the tract names that are available:\n",
    "print(df_tract_patch_visit.tract.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The repo consists of three visits: 9615, 9697, and 9813."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some visit/tract/patch combinations from these at random:\n",
    "numvisits = 12\n",
    "patch_sel = df_tract_patch_visit.sample(numvisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCDs number from 0-111. Randomly select a CCD for each of the visits:\n",
    "ccdnums = np.random.randint(112, size=numvisits)\n",
    "\n",
    "# CCD 9 is bad, so generate a new array until we have no \"9\" values in it:\n",
    "exclude_ccds = [9]\n",
    "while ccdnums.any() in exclude_ccds:\n",
    "    ccdnums = np.random.randint(112, size=numvisits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_id = 0\n",
    "calexps = []\n",
    "datarefs = []\n",
    "\n",
    "for row, vis in patch_sel.iterrows():\n",
    "    # print(vis)\n",
    "    # Note: we are using only the 'HSC-R' filter for this, but other filters could be selected:\n",
    "    dataref = {'tract':int(vis.tract),'visit':int(vis.visit), 'ccd':int(ccdnums[ccd_id])}\n",
    "    calexp = butler.get('calexp', dataId = dataref)\n",
    "    ccd_id += 1\n",
    "    calexps.append(calexp)\n",
    "    datarefs.append(dataref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a simple way to confirm that a given `calexp` image has a PSF is via the method: `calexp.hasPsf()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each of the selected visit/tract/patch/CCD combinations, pick a random (X,Y) coordinate, extract the PSF, and plot an image of the PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = numvisits/ncols # 4 plots per row\n",
    "f, ax = plt.subplots(nrows=int(np.ceil(nrows)), ncols=int(ncols), sharey=True, sharex=True, figsize=(12,10))\n",
    "axnum = 0\n",
    "axs = ax.flatten()\n",
    "\n",
    "for c in calexps:\n",
    "#    print(c.hasPsf())\n",
    "    psf = calexp.getPsf()\n",
    "    xsize = c.getDimensions().getX()\n",
    "    ysize = c.getDimensions().getY()\n",
    "    # Select a random point on the image and extract the PSF at that point:\n",
    "    xpt = random.random()*xsize\n",
    "    ypt = random.random()*ysize\n",
    "    psfimage = psf.computeImage(geom.PointD(xpt, ypt))\n",
    "    img = psfimage.array\n",
    "\n",
    "    # Create an ImageNormalize object\n",
    "    norm = ImageNormalize(img, interval=MinMaxInterval(),\n",
    "                          stretch=LogStretch())\n",
    "\n",
    "#    axs[axnum].set_xlim(psfimage.getX0(),psfimage.getX0()+psfimage.getDimensions()[0])\n",
    "#    axs[axnum].set_ylim(psfimage.getY0(),psfimage.getY0()+psfimage.getDimensions()[1])\n",
    "    axs[axnum].set_title('visit: '+patch_sel.iloc[axnum].visit+';\\n (x,y)=('+str(round(xpt,1))+', '+str(round(ypt,1))+')')\n",
    "    axs[axnum].imshow(img, norm=norm, origin='lower')\n",
    "    axnum += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now confirm that the PSF is reasonably well-matched to stellar images by selecting a star in each image and subtracting the PSF at the star's position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a bright star that was used to fit the PSF, and one that was used to calibrate the photometry:\n",
    "src = butler.get('src', dataId=dataref)\n",
    "\n",
    "# Select a PSF and photometric calibration stars:\n",
    "psf_selection = src['calib_psf_used']\n",
    "photcalib_selection = src['calib_photometry_used']\n",
    "\n",
    "# Pick one from each table at random:\n",
    "psf_src = random.choice(src[psf_selection])\n",
    "photcalib_src = random.choice(src[photcalib_selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radec_psf_src = psf_src.getCoord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs = c.getWcs()\n",
    "\n",
    "cutoutSize = geom.ExtentI(100, 100) # size of cutout in pixels\n",
    "xy = geom.Point2I(wcs.skyToPixel(radec_psf_src)) # central XY coordinate of our star's RA, Dec position\n",
    "\n",
    "# Create the bounding box:\n",
    "bbox = geom.Box2I(xy - cutoutSize//2, cutoutSize)\n",
    "\n",
    "# Full patch image\n",
    "#image = butler.get('calexp', immediate=True, dataId=dataid)\n",
    "# Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "xy0 = c.getXY0() \n",
    "\n",
    "# Postage stamp image only, using the bbox defined above:\n",
    "cutout_image = butler.get('calexp_sub', bbox=bbox, immediate=True, dataId=dataref).getMaskedImage()\n",
    "# Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "xy0_cutout = cutout_image.getXY0() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = c.getPsf()\n",
    "model = Exposure(cutout_image.getBBox(), dtype=np.float32)\n",
    "model.setPsf(psf)\n",
    "psfImage = psf.computeImage(psf_src.getCentroid())\n",
    "flux = psf_src['base_PsfFlux_instFlux']-(psf_src['base_PsfFlux_area']*psf_src['base_LocalBackground_instFlux'])\n",
    "psfBBox = psfImage.getBBox()\n",
    "model.image[psfBBox, PARENT].scaledPlus(flux, psfImage.convertF())\n",
    "residuals = cutout_image.clone()\n",
    "residuals.image -= model.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=3, sharey=True, sharex=True, figsize=(12,6))\n",
    "axs = ax.flatten()\n",
    "\n",
    "vmin0, vmax0 = zscale.get_limits(cutout_image.image.array)\n",
    "# Get the dimensions of the image so we can set plot limits\n",
    "imsize = cutout_image.getDimensions()\n",
    "axs[0].imshow(cutout_image.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "# Set the plot range to the dimensions:\n",
    "axs[0].set_xlim(0,imsize[0])\n",
    "axs[0].set_ylim(0,imsize[1])\n",
    "axs[0].set_title('Original image')\n",
    "#axs[0].colorbar()\n",
    "#axs[0].xlabel('X (pix)')\n",
    "#axs[0].ylabel('Y (pix)')\n",
    "axs[0].scatter(xy.getX()-xy0_cutout.getX(), xy.getY()-xy0_cutout.getY(), color='none', edgecolor='magenta', s=2000, linewidth=5)\n",
    "#plt.title('(RA, Dec) = ('+str(ratest)+', '+str(dectest)+'), field '+str(allfieldnames[ccdfind])+', visit: '+str(allvisits[ccdfind])+', CCD: '+str(allccdnumbers[ccdfind]),fontsize=14)\n",
    "\n",
    "#vmin, vmax = zscale.get_limits(model.image.array)\n",
    "#vmin, vmax = zscale.get_limits(psfImage.array)\n",
    "# Get the dimensions of the image so we can set plot limits\n",
    "#imsize = psfImage.getDimensions()\n",
    "imsize = model.image.getDimensions()\n",
    "axs[1].imshow(model.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "#axs[1].imshow(psfImage.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "# Set the plot range to the dimensions:\n",
    "axs[1].set_xlim(0,imsize[0])\n",
    "axs[1].set_ylim(0,imsize[1])\n",
    "axs[1].set_title('Scaled PSF')\n",
    "#axs[1].colorbar()\n",
    "#axs[1].xlabel('X (pix)')\n",
    "#axs[1].ylabel('Y (pix)')\n",
    "#axs[1].scatter(xy.getX()-xy0_cutout.getX(), xy.getY()-xy0_cutout.getY(), color='none', edgecolor='magenta', s=2000, linewidth=5)\n",
    "#plt.title('(RA, Dec) = ('+str(ratest)+', '+str(dectest)+'), field '+str(allfieldnames[ccdfind])+', visit: '+str(allvisits[ccdfind])+', CCD: '+str(allccdnumbers[ccdfind]),fontsize=14)\n",
    "\n",
    "#vmin, vmax = zscale.get_limits(residuals.image.array)\n",
    "# Get the dimensions of the image so we can set plot limits\n",
    "imsize = residuals.image.getDimensions()\n",
    "axs[2].imshow(residuals.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "# Set the plot range to the dimensions:\n",
    "axs[2].set_xlim(0,imsize[0])\n",
    "axs[2].set_ylim(0,imsize[1])\n",
    "axs[2].set_title('PSF subtracted')\n",
    "\n",
    "#axs[1].colorbar()\n",
    "#axs[1].xlabel('X (pix)')\n",
    "#axs[1].ylabel('Y (pix)')\n",
    "axs[2].scatter(xy.getX()-xy0_cutout.getX(), xy.getY()-xy0_cutout.getY(), color='none', edgecolor='magenta', s=2000, linewidth=5)\n",
    "#plt.title('(RA, Dec) = ('+str(ratest)+', '+str(dectest)+'), field '+str(allfieldnames[ccdfind])+', visit: '+str(allvisits[ccdfind])+', CCD: '+str(allccdnumbers[ccdfind]),fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = numvisits # 4 plots per row\n",
    "f, ax = plt.subplots(nrows=int(nrows), ncols=int(ncols), sharey=True, sharex=True, figsize=(5,24))\n",
    "axnum = 0\n",
    "axs = ax.flatten()\n",
    "plt.rcParams.update({'font.size' : 10})\n",
    "\n",
    "for i in range(len(calexps)):\n",
    "# for c in calexps:\n",
    "    c = calexps[i]\n",
    "    dataid = datarefs[i]\n",
    "    # Pick a bright star that was used to fit the PSF:\n",
    "    src = butler.get('src', dataId=dataid)\n",
    "\n",
    "    # Get the WCS for this calexp:\n",
    "    wcs = c.getWcs()\n",
    "\n",
    "    # size of image cutout in pixels\n",
    "    imsize = 100\n",
    "    cutoutSize = geom.ExtentI(imsize, imsize)\n",
    "\n",
    "    # Select a PSF star:\n",
    "    psf_selection = src['calib_psf_used']\n",
    "\n",
    "    # Pick one from the table at random, but require it to have coordinates\n",
    "    #   such that the bounding box will not extend beyond the CCD's border:\n",
    "    oksrc = False\n",
    "    while not oksrc:\n",
    "        calexp_dimen = c.getDimensions()\n",
    "        psf_src = random.choice(src[psf_selection])\n",
    "        xy = psf_src.getCentroid()\n",
    "        if (xy.getX() > imsize/2.0) and (xy.getX() < calexp_dimen[0]-imsize/2.0) and\\\n",
    "           (xy.getY() > imsize/2.0) and (xy.getY() < calexp_dimen[1]-imsize/2.0):\n",
    "            oksrc = True\n",
    "\n",
    "            \n",
    "    xy = geom.Point2I(xy)\n",
    "\n",
    "    # Create the bounding box:\n",
    "    bbox = geom.Box2I(xy - cutoutSize//2, cutoutSize)\n",
    "\n",
    "    # Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "    xy0 = c.getXY0() \n",
    "\n",
    "    # Postage stamp image only, using the bbox defined above:\n",
    "    cutout_image = butler.get('calexp_sub', bbox=bbox, immediate=True, dataId=dataid).getMaskedImage()\n",
    "    # Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "    xy0_cutout = cutout_image.getXY0() \n",
    "    \n",
    "    psf = c.getPsf()\n",
    "    model = Exposure(cutout_image.getBBox(), dtype=np.float32)\n",
    "    model.setPsf(psf)\n",
    "    psfImage = psf.computeImage(psf_src.getCentroid())\n",
    "    flux = psf_src['base_PsfFlux_instFlux']-(psf_src['base_PsfFlux_area']*psf_src['base_LocalBackground_instFlux'])\n",
    "    psfBBox = psfImage.getBBox()\n",
    "    model.image[psfBBox, PARENT].scaledPlus(flux, psfImage.convertF())\n",
    "    residuals = cutout_image.clone()\n",
    "    residuals.image -= model.image\n",
    "    \n",
    "    vmin0, vmax0 = zscale.get_limits(cutout_image.image.array)\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = cutout_image.getDimensions()\n",
    "    axs[axnum].imshow(cutout_image.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('Original image')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "\n",
    "    axnum += 1\n",
    "\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = model.image.getDimensions()\n",
    "    axs[axnum].imshow(model.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('Scaled PSF')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "    \n",
    "    axnum += 1\n",
    "\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = residuals.image.getDimensions()\n",
    "    axs[axnum].imshow(residuals.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('PSF subtracted')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "\n",
    "    axnum += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = numvisits # 4 plots per row\n",
    "f, ax = plt.subplots(nrows=int(nrows), ncols=int(ncols), sharey=True, sharex=True, figsize=(5,24))\n",
    "axnum = 0\n",
    "axs = ax.flatten()\n",
    "plt.rcParams.update({'font.size' : 10})\n",
    "\n",
    "for i in range(len(calexps)):\n",
    "# for c in calexps:\n",
    "    c = calexps[i]\n",
    "    dataid = datarefs[i]\n",
    "    # Pick a bright star that was used to fit the PSF:\n",
    "    src = butler.get('src', dataId=dataid)\n",
    "\n",
    "    # Get the WCS for this calexp:\n",
    "    wcs = c.getWcs()\n",
    "\n",
    "    # size of image cutout in pixels\n",
    "    imsize = 100\n",
    "    cutoutSize = geom.ExtentI(imsize, imsize)\n",
    "\n",
    "    # Select a photometric calibration star:\n",
    "    photcalib_selection = src['calib_photometry_used']\n",
    "\n",
    "    # Pick one from the table at random, but require it to have coordinates\n",
    "    #   such that the bounding box will not extend beyond the CCD's border:\n",
    "    oksrc = False\n",
    "    while not oksrc:\n",
    "        calexp_dimen = c.getDimensions()\n",
    "        photcalib_src = random.choice(src[photcalib_selection])\n",
    "        xy = photcalib_src.getCentroid()\n",
    "        if (xy.getX() > imsize/2.0) and (xy.getX() < calexp_dimen[0]-imsize/2.0) and\\\n",
    "           (xy.getY() > imsize/2.0) and (xy.getY() < calexp_dimen[1]-imsize/2.0):\n",
    "            oksrc = True\n",
    "\n",
    "            \n",
    "    xy = geom.Point2I(xy)\n",
    "\n",
    "    # Create the bounding box:\n",
    "    bbox = geom.Box2I(xy - cutoutSize//2, cutoutSize)\n",
    "\n",
    "    # Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "    xy0 = c.getXY0() \n",
    "\n",
    "    # Postage stamp image only, using the bbox defined above:\n",
    "    cutout_image = butler.get('calexp_sub', bbox=bbox, immediate=True, dataId=dataid).getMaskedImage()\n",
    "    # Because an entire tract shares a WCS, the corner of the patch (or cutout) isn't necessarily at (X,Y)=(0,0). Get the XY0 pixel values:\n",
    "    xy0_cutout = cutout_image.getXY0() \n",
    "    \n",
    "    psf = c.getPsf()\n",
    "    model = Exposure(cutout_image.getBBox(), dtype=np.float32)\n",
    "    model.setPsf(psf)\n",
    "    psfImage = psf.computeImage(photcalib_src.getCentroid())\n",
    "    flux = photcalib_src['base_PsfFlux_instFlux']-(photcalib_src['base_PsfFlux_area']*photcalib_src['base_LocalBackground_instFlux'])\n",
    "    psfBBox = psfImage.getBBox()\n",
    "    model.image[psfBBox, PARENT].scaledPlus(flux, psfImage.convertF())\n",
    "    residuals = cutout_image.clone()\n",
    "    residuals.image -= model.image\n",
    "    \n",
    "    vmin0, vmax0 = zscale.get_limits(cutout_image.image.array)\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = cutout_image.getDimensions()\n",
    "    axs[axnum].imshow(cutout_image.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('Original image')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "\n",
    "    axnum += 1\n",
    "\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = model.image.getDimensions()\n",
    "    axs[axnum].imshow(model.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('Scaled PSF')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "    \n",
    "    axnum += 1\n",
    "\n",
    "    # Get the dimensions of the image so we can set plot limits\n",
    "    imsize = residuals.image.getDimensions()\n",
    "    axs[axnum].imshow(residuals.image.array, vmin=vmin0, vmax=vmax0, cmap='binary')\n",
    "    # Set the plot range to the dimensions:\n",
    "    axs[axnum].set_xlim(0,imsize[0])\n",
    "    axs[axnum].set_ylim(0,imsize[1])\n",
    "    axs[axnum].set_title('PSF subtracted')\n",
    "    axs[axnum].get_xaxis().set_visible(False)\n",
    "    axs[axnum].get_yaxis().set_visible(False)\n",
    "\n",
    "    axnum += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im0 = psfimage.array\n",
    "norm = ImageNormalize(img, interval=MinMaxInterval(),\n",
    "                      stretch=AsinhStretch(),vmin=0, vmax=1e-9)\n",
    "\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=patch_sel.iloc[0].visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'{%.3f}'.format(xpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0.set_xlabel(psfimage.getX0(),psfimage.getX0()+psfimage.getDimensions()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = butler.subset('calexp', filter='HSC-R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What field names are in this dataset?\n",
    "fields = set( [x['field'] for x in sss.cache])\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could remove \"TEST,\" \"HSC-R,\" \"DOMEFLAT,\" \"DARK,\" \"SKYFLAT,\" \"BIAS,\" and \"FOCUSING\" from the set of fields. But instead, let's just grab the \"M31\" field for these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss2 = butler.subset('calexp', filter='HSC-R', field='M31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss2.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss.cache[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = sss.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sss2 = {key:val for key, val in sss.cache.items() if val!='SKYFLAT'}\n",
    "#sss2 = [x for x in sss.cache if x['field'] != 'SKYFLAT']\n",
    "aaa2 = [x for x in aaa if not 'FLAT' in x['field']]\n",
    "fields = set( [x['field'] for x in aaa2])# if True])\n",
    "ccds = set( [x['ccd'] for x in aaa2])# if True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(aaa),len(aaa2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fields = list(set(val for val in aaa2)) \n",
    "ccds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.choice(m31_fields.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for visnum in range(numvisits):\n",
    "    print(visnum)\n",
    "    dataref = random.choice(m31_fields.cache)\n",
    "#    print(row)\n",
    "    # Note: we are using only the 'HSC-R' filter for this, but other filters could be selected:\n",
    "#    dataref = {'visit':int(vis.visit),'filter':'HSC-R', 'ccd':ccdnums[ccd_id]}\n",
    "#    dataref = {'tract':vis.tract,'patch':vis.patch,'visit':int(vis.visit),'filter':'HSC-R', 'ccd':ccdnums[ccd_id]}\n",
    "    calexp = butler.get('calexp', dataId = dataref)\n",
    "#    ccd_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = df_tract_patch_visit.values[0]\n",
    "ddd = {'visit':int(df_tract_patch_visit.visit[0]), 'tract':int(df_tract_patch_visit.tract[0]), 'ccd':33}\n",
    "cc = butler.get('calexp', dataId=ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
