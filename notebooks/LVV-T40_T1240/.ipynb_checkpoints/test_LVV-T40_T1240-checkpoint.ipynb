{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test notebook for Acceptance Test Campaign related to LSST Science Pipelines Release 19.0.0\n",
    "\n",
    "This test will be executed on the LSST Science Platform Notebook Aspect, initialized with Science Pipelines release `r19-0-0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case LVV-T40: Verify implementation of Generate WCS for Visit Images\n",
    "Verify that Processed Visit Images produced by the AP and DRP pipelines include FITS WCS accurate to specified **astrometricAccuracy** over the bounds of the image.\n",
    "\n",
    "### Test case LVV-T1240: Verify implementation of minimum astrometric standards per CCD\n",
    "Verify that each CCD in a processed dataset had its astrometric solution determined by at least **astrometricMinStandards = 5** astrometric standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "For this test we interpret the requirement to mean that the _absolute_ astrometry (as compared to an external reference source of \"truth\" such as Gaia DR2) should meet the specified accuracy. Thus the verification will be done by comparing to Gaia DR2 (note, however, that the HSC-RC2 data were astrometrically and photometrically calibrated to PanSTARRS-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the version of the Science Pipelines is v19_0_0:\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.persistence as dafPersist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.gaia import Gaia\n",
    "from astropy.visualization import (MinMaxInterval, AsinhStretch, ZScaleInterval, LogStretch, LinearStretch,\n",
    "                                   ImageNormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "zscale = ZScaleInterval()\n",
    "\n",
    "# Set up some plotting defaults:\n",
    "plt.rcParams.update({'figure.figsize' : (12, 8)})\n",
    "plt.rcParams.update({'font.size' : 24})\n",
    "plt.rcParams.update({'axes.linewidth' : 3})\n",
    "plt.rcParams.update({'axes.labelweight' : 3})\n",
    "plt.rcParams.update({'axes.titleweight' : 5})\n",
    "plt.rcParams.update({'ytick.major.width' : 3})\n",
    "plt.rcParams.update({'ytick.minor.width' : 2})\n",
    "plt.rcParams.update({'ytick.major.size' : 8})\n",
    "plt.rcParams.update({'ytick.minor.size' : 5})\n",
    "plt.rcParams.update({'xtick.major.size' : 8})\n",
    "plt.rcParams.update({'xtick.minor.size' : 5})\n",
    "plt.rcParams.update({'xtick.major.width' : 3})\n",
    "plt.rcParams.update({'xtick.minor.width' : 2})\n",
    "plt.rcParams.update({'xtick.direction' : 'in'})\n",
    "plt.rcParams.update({'ytick.direction' : 'in'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use HSC-RC2, as processed using `w_2019_46`, which is the pipelines version that was used to create `v19_0_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output repo is tagged with the Jira ticket number \"DM-22223\":\n",
    "\n",
    "rc2_repo = '/datasets/hsc/repo/rerun/RC/w_2019_46/DM-22223-sfm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the butler repo:\n",
    "butler = dafPersist.Butler(rc2_repo)\n",
    "\n",
    "# Make a glob of the files in the repo, so we can parse this to get tract/patch IDs:\n",
    "infiles = glob.glob(rc2_repo+'/*/*/corr/CORR*.fits')\n",
    "# /datasets/hsc/repo/rerun/RC/w_2019_46/DM-22223-sfm/01172/HSC-R/corr\n",
    "print(len(infiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make arrays of the tract, patch numbers by parsing the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_array = []\n",
    "ccd_array = []\n",
    "visit_array = []\n",
    "tract_array = []\n",
    "\n",
    "# Each line of \"infiles\" looks like this (infile[0]):\n",
    "# /datasets/hsc/repo/rerun/RC/w_2019_46/DM-22223-sfm/01172/HSC-R/corr/CORR-0030500-037.fits\n",
    "\n",
    "# Split on the '/', then parse the resulting array. Here's the result of infiles[0].split('/'):\n",
    "\n",
    "#['',\n",
    "# 'datasets',\n",
    "# 'hsc',\n",
    "# 'repo',\n",
    "# 'rerun',\n",
    "# 'RC',\n",
    "# 'w_2019_46',\n",
    "# 'DM-22223-sfm',\n",
    "# '01170',\n",
    "# 'HSC-Z',\n",
    "# 'corr',\n",
    "# 'CORR-0023226-028.fits']\n",
    "\n",
    "# So the tract number is third from the end, and patch is second from the end.\n",
    "\n",
    "for ii in range(0, len(infiles)):\n",
    "    parts = infiles[ii].split('/')\n",
    "    # Only keep ones with filters starting with 'HSC' (ditch the narrow-band filters):\n",
    "    if np.str.startswith(parts[-3], 'HSC'):\n",
    "        tract_array.append(int(parts[-4]))\n",
    "        filt_array.append(parts[-3])\n",
    "        # Split the file name to extract the visit number:\n",
    "        file_str = parts[-1]\n",
    "        file_str2 = file_str.split('.fits')\n",
    "        file_str3 = file_str2[0].split('-')\n",
    "        visit_array.append(int(file_str3[-2]))\n",
    "        ccd_array.append(int(file_str3[-1]))\n",
    "\n",
    "print('Found %i images'%(len(ccd_array)))\n",
    "        \n",
    "# Assemble in pandas data frame    \n",
    "data = {'tract': tract_array,\n",
    "        'filter': filt_array,\n",
    "        'ccd': ccd_array,\n",
    "        'visit': visit_array}\n",
    "df_filter_ccd_visit = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter_ccd_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the CCD numbers that are available:\n",
    "print(df_filter_ccd_visit.ccd.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would take a prohibitively long time to check every CCD from every visit, so we will randomly select a subset to test. For now, the test is using `astroquery` to match to Gaia, but implementing a more direct match to the Gaia database on lsst-dev would likely streamline the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haswcs_flags = []\n",
    "num_calib_astrom = []\n",
    "median_mag_astrom = []\n",
    "datarefs = []\n",
    "medianAstromOffsets = []\n",
    "numGaiaMatches = []\n",
    "\n",
    "# Select some visit/ccd combinations from these at random:\n",
    "numvisits = 500 # 100 runs in a few min. 500 takes ~0.5 hr.\n",
    "visit_sel = df_filter_ccd_visit.sample(numvisits)\n",
    "\n",
    "for row, vis in visit_sel.iterrows():\n",
    "    # print(vis)\n",
    "    dataref = {'tract':vis['tract'], 'filter':vis['filter'], 'visit':vis['visit'], 'ccd':vis['ccd']}\n",
    "    # Sometimes CCDs fail, so test whether the dataset exists before grabbing it:\n",
    "    if butler.datasetExists('calexp', dataId = dataref):\n",
    "        calexp = butler.get('calexp', dataId = dataref)\n",
    "        haswcs_flags.append(butler.get('calexp', dataId = dataref).hasWcs())\n",
    "#        haswcs_flags.append(butler.datasetExists('calexp_wcs', dataId = dataref))\n",
    "\n",
    "        # Check how many objects were used to calibrate the astrometry:\n",
    "        src = butler.get('src', dataId = dataref)\n",
    "        astrom_selection = np.where(src['calib_astrometry_used'] == True)\n",
    "        num_calib_astrom.append(np.size(astrom_selection))\n",
    "        calexp_calib = butler.get('calexp_photoCalib', dataId=dataref)\n",
    "        src_mag = calexp_calib.instFluxToMagnitude(src, 'base_PsfFlux')\n",
    "\n",
    "        median_mag_astrom.append(np.median(src_mag[astrom_selection,0]))\n",
    "\n",
    "        # Extract the WCS+calexp and match to Gaia:\n",
    "        wcs = calexp.getWcs()\n",
    "        center = wcs.pixelToSky(calexp.getX0()+calexp.getWidth()/2.0, calexp.getY0()+calexp.getHeight()/2.0)\n",
    "        pscale = wcs.getPixelScale()\n",
    "        width = calexp.getWidth()*pscale.asDegrees()\n",
    "        height = calexp.getHeight()*pscale.asDegrees()\n",
    "#        wcs = butler.get('calexp_wcs', dataId = dataref)\n",
    "        cen = SkyCoord(center.getRa().asDegrees()*u.degree, center.getDec().asDegrees()*u.degree)\n",
    "        width = u.Quantity(width, u.deg)\n",
    "        height = u.Quantity(height, u.deg)\n",
    "\n",
    "        gaia_mch = Gaia.query_object_async(coordinate=cen, width=width, height=height)\n",
    "        # gaia_mch.pprint()\n",
    "        sc_src = SkyCoord(src['coord_ra']*u.rad, src['coord_dec']*u.rad)\n",
    "        sc_gaia = SkyCoord(gaia_mch['ra'], gaia_mch['dec'])\n",
    "        src_match = sc_src.match_to_catalog_sky(sc_gaia)\n",
    "        sep_match = src_match[1]\n",
    "        \n",
    "        gaia_gmag = gaia_mch['phot_g_mean_mag']\n",
    "        # gaia_bpmag = gaia_mch['phot_bp_mean_mag']\n",
    "        # gaia_rpmag = gaia_mch['phot_rp_mean_mag']\n",
    "        \n",
    "        okmch = (sep_match.arcsec < 2.0)\n",
    "        matchsep = sep_match[okmch]\n",
    "        \n",
    "        # Require the matches to have similar magnitudes:\n",
    "        magdiff = src_mag[okmch][:,0]-gaia_gmag[src_match[0][okmch]]\n",
    "        \n",
    "        okmagdiff = (np.abs(magdiff - np.median(magdiff)) < 1.0)\n",
    "        okmatchsep = matchsep[okmagdiff]\n",
    "        \n",
    "        medianOffset = np.median(np.array(okmatchsep.marcsec))\n",
    "        medianAstromOffsets.append(medianOffset)\n",
    "        numGaiaMatches.append(np.size(okmatchsep))\n",
    "\n",
    "        # Save the datarefs for later:\n",
    "        datarefs.append(dataref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the outputs of the previous cell to numpy arrays:\n",
    "numGaiaMatches = np.array(numGaiaMatches)\n",
    "medianAstromOffsets = np.array(medianAstromOffsets)\n",
    "num_calib_astrom = np.array(num_calib_astrom)\n",
    "median_mag_astrom = np.array(median_mag_astrom)\n",
    "\n",
    "# Keep only the CCDs with at least one Gaia match:\n",
    "okmch = np.where(numGaiaMatches >= 1)\n",
    "\n",
    "nGaiaMatches = numGaiaMatches[okmch[0]]\n",
    "medAstromOffsets = medianAstromOffsets[okmch[0]]\n",
    "n_calib_astrom = num_calib_astrom[okmch[0]]\n",
    "med_mag_astrom = median_mag_astrom[okmch[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did all of the CCDs use more than `astrometricMinStandards` = 5 standards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of fields that used > 5 standards for astrometric calibration:\n",
    "wcsFlagsPercent = (np.size(np.where(haswcs_flags))/np.size(haswcs_flags))*100.0*u.percent\n",
    "print('Percentage of fields with > astrometricMinStandards=5: ', wcsFlagsPercent,' -- ',wcsFlagsPercent == 100.0*u.percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraction of CCDs meeting the `astrometricAccuracy` threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of CCDs that meet the requirement:\n",
    "astrometricAccuracy = 50.0 # 50 mas is the threshold in the requirement\n",
    "astromMeetsThreshPercent = (np.size(np.where(medAstromOffsets < astrometricAccuracy))/np.size(medAstromOffsets))*100.0*u.percent\n",
    "print('Percentage of fields meeting the threshold: ', astromMeetsThreshPercent,' -- ',astromMeetsThreshPercent == 100.0*u.percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion, figures:\n",
    "For any random selection of CCDs on which we calculate this, a small fraction do not meet the threshold. This may have more to do with the matching to Gaia than the accuracy of the WCS. Let's explore..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the median value of the astrometric residuals (vs. Gaia) to the number of Gaia sources matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(medianAstromOffsets, numGaiaMatches)\n",
    "plt.plot(nGaiaMatches, medAstromOffsets, 'k.', ms=15)\n",
    "plt.xlabel('number of Gaia matches')\n",
    "plt.ylabel('median astrometric residual (mas)')\n",
    "plt.hlines(astrometricAccuracy, 0, 100, linestyle='dashed', label='Requirement')\n",
    "plt.xlim(0,np.max(nGaiaMatches)*1.1)\n",
    "plt.ylim(0,np.max(medAstromOffsets)*1.1)\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the objects with high residuals are those that have few Gaia matches. Do they also have few astrometric calibrators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_calib_astrom, medAstromOffsets, 'k.', ms=15)\n",
    "plt.xlabel('number of astrometric calibrators')\n",
    "plt.ylabel('median astrometric residual (mas)')\n",
    "plt.hlines(astrometricAccuracy, 0, 1000, linestyle='dashed', label='Requirement')\n",
    "plt.xlim(0,np.max(n_calib_astrom)*1.1)\n",
    "plt.ylim(0,np.max(medAstromOffsets)*1.1)\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it seems that many of the fields with large residuals have large numbers of calibrators (and _all_ have > 50).\n",
    "\n",
    "Furthermore, there seem to be too few Gaia matches per CCD to be able to split them into smaller spatial regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the median magnitude of sources that contributed to the astrometric solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to try to understand the previous two plots, check the median mag of astrometric calibrators:\n",
    "plt.plot(med_mag_astrom, medAstromOffsets, 'k.', ms=15)\n",
    "plt.xlabel('median mag of astrometric calibrators')\n",
    "plt.ylabel('median astrometric residual (mas)')\n",
    "plt.hlines(astrometricAccuracy, 0, 1000, linestyle='dashed', label='Requirement')\n",
    "plt.xlim(np.min(med_mag_astrom)*0.95,np.max(med_mag_astrom)*1.05)\n",
    "plt.ylim(0,np.max(medAstromOffsets)*1.1)\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the fields with large astrometric residuals when compared to Gaia were calibrated using faint stars. These may be deep exposures, so that many Gaia objects saturate, or some other similar effect. Because of this small fraction of fields, the test for LVV-T40 technically does not pass. Given that this may be due to a lack of Gaia reference catalog objects, and not due to a deficiency in DM algorithms, we consider the result of this test __\"Pass With Deviations.\"__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
